{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_K7F19SPQo6U",
        "9YLXvK51RnuL",
        "AHmjSVf_FNHv",
        "gPXJkNubFyY6",
        "iD45m3IwF9hh",
        "IoA0tZZCa_1k"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88a013142de04e2cb1f9e2892da8266a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45e046c53e8c4ed7b28e4e2e4b14eca4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2415c3503a364773aa247e4f3594198c",
              "IPY_MODEL_d92ab09330ac487bb808acffbd05697e"
            ]
          }
        },
        "45e046c53e8c4ed7b28e4e2e4b14eca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2415c3503a364773aa247e4f3594198c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40f606ed1d314a418a41a11e611ed72f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 165140,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 165140,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1a69607289f4407be259e4eb4ad9e4d"
          }
        },
        "d92ab09330ac487bb808acffbd05697e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ecf2bab890ab41e1a697c14f4e1820db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 165888/? [00:46&lt;00:00, 3566.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea9e2f68b9ca4d559dd54e66843784b2"
          }
        },
        "40f606ed1d314a418a41a11e611ed72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1a69607289f4407be259e4eb4ad9e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecf2bab890ab41e1a697c14f4e1820db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea9e2f68b9ca4d559dd54e66843784b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpt777/CS474/blob/main/lab10_unfreezing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEwpv0GZ_CrT"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab10.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnoEhAVvBcMj"
      },
      "source": [
        "# Lab 10: Transfer Learning/Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBOvJdJfkXIL"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiuvTUWOjtBC"
      },
      "source": [
        "### Objective\n",
        "\n",
        "- Gain experience fine-tuning pre-trained models to domain-specific applications.\n",
        "\n",
        "### Deliverable\n",
        "\n",
        "For this lab you will submit an ipython notebook via learning suite. The bulk of the work is in modifying fine-tuning a pre-trained ResNet. Fine-tuning the GPT-2 language model is pretty easy. The provided code works as is; you will just have to swap in your own text dataset.\n",
        "\n",
        "### Grading\n",
        "\n",
        "- 35% Create a dataset class for your own dataset\n",
        "- 35% Create a network class that wraps a pretrained ResNet\n",
        "- 20% Implement unfreezing in the network class\n",
        "- 10% Fine-tune GPT-2 on your own dataset\n",
        "\n",
        "### Tips\n",
        "- Your life will be better if you download a dataset that already has the data in the expected format for ImageFolder (make sure to read the documentation!). The datasets recommended below are in the correct format.\n",
        "- Get the CNN working on the provided dataset (bird species classification) before swapping in your own.\n",
        "- For reference on freezing/unfreezing network weights, see [this github gist](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c)\n",
        "- For training GPT-2, first try the medium-size (355M parameter) model. If your Colab instance doesn't have enough GPU space, you may need to switch to the small-size (124M parameter) model, but the results will be less impressive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKzRORuLBNLR"
      },
      "source": [
        "from torchvision.models import resnet152\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4R3D8Mr8b54"
      },
      "source": [
        "## 1 Fine-tune a ResNet for image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFoEeTYHDq2s"
      },
      "source": [
        "### 1.1 Find a dataset to fine-tune on, and make a Dataset class (1 hr.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z6g7a_Y84n0"
      },
      "source": [
        "#### Done:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8NtFZRd5hcm"
      },
      "source": [
        "- Inherit from torch.utils.data.Dataset\n",
        "- Use a [torchvision.datasets.ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder)\n",
        "- Don't spend too long finding another dataset. Some suggestions that you are free to use:\n",
        " - https://www.kaggle.com/jessicali9530/stanford-dogs-dataset\n",
        " - https://www.kaggle.com/puneet6060/intel-image-classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBigIUFTukeJ"
      },
      "source": [
        "#### Help for downloading kaggle datasets\n",
        "Downloading Kaggle datasets requires authentication, so you can't just download from a url. Here are some step-by-step instructions of how to get Kaggle datasets in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X29UC6CvwfQ"
      },
      "source": [
        "1. Create an API key in Kaggle\n",
        "    - Click on profile photo\n",
        "    - Go to 'My Account'\n",
        "    - Scroll down to the API access section and click \"Create New API Token\"\n",
        "    - `kaggle.json` is now downloaded to your computer\n",
        "\n",
        "2. Upload the API key and install the Kaggle API client by running the next cell (run it again if it throws an error the first time). Also, `files.upload()` may not work in Firefox. One solution is to expand the Files banner (indicated by the '>' tab on the left side of the page) and use that to upload the key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Mhjc0pM7jOoZ",
        "outputId": "ba8a3cf4-de0d-40ae-cc52-8053fac08605"
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle\n",
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7ccccbe-d2c9-49f4-80cd-2b82b5228add\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b7ccccbe-d2c9-49f4-80cd-2b82b5228add\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "-rw-r--r-- 1 root root 69 Mar 19 03:01 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGlIa4SIwEXB"
      },
      "source": [
        "3. Copy the desired dataset locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HtB-XdIr1EE",
        "outputId": "42e03162-dd02-4f2a-e260-68b85156cb5d"
      },
      "source": [
        "# Example download command for dataset found here: https://www.kaggle.com/akash2907/bird-species-classification\n",
        "!kaggle datasets download -d akash2907/bird-species-classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading bird-species-classification.zip to /content\n",
            " 99% 1.36G/1.37G [00:05<00:00, 266MB/s]\n",
            "100% 1.37G/1.37G [00:05<00:00, 252MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcz0JGXjxFGe"
      },
      "source": [
        "#### Make the Dataset class\n",
        "See the implementation below for reference, and implement a dataset class for the dataset you choose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "lthPlsGeK4CX",
        "outputId": "f8135fe2-d540-40a9-fcc3-e558b20238d8"
      },
      "source": [
        "class BirdDataset(Dataset):\n",
        "    def __init__(self, zip_file='bird-species-classification.zip', size=256, train=True, upload=False):\n",
        "        super(BirdDataset, self).__init__()\n",
        "        \n",
        "        self.train = train\n",
        "        extract_dir = os.path.splitext(zip_file)[0]\n",
        "        if not os.path.exists(extract_dir):\n",
        "            os.makedirs(extract_dir)\n",
        "            self.extract_zip(zip_file, extract_dir)\n",
        "            # Resize the images - originally they are high resolution. We could do this\n",
        "            # in the DataLoader, but it will read the full-resolution files from disk\n",
        "            # every time before resizing them, making training slow\n",
        "            self.resize(extract_dir, size=size)\n",
        "\n",
        "        postfix = 'train' if train else 'test'\n",
        "            \n",
        "        if train:\n",
        "            # The bird-species dataset mistakenly has a train_data folder inside of train_data\n",
        "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'train_data', 'train_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        else:\n",
        "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'test_data', 'test_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "    def extract_zip(self, zip_file, extract_dir):\n",
        "        print(\"Extracting\", zip_file)\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "    def resize(self, path, size=256):\n",
        "        \"\"\"Resizes all images in place\"\"\"\n",
        "        print(\"Resizing images\")\n",
        "        dirs = os.walk(path)\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for item in files:\n",
        "                name = os.path.join(root, item)\n",
        "                if os.path.isfile(name):\n",
        "                    im = Image.open(name)\n",
        "                    im = ImageOps.fit(im, (size, size))\n",
        "                    im.save(name[:-3] + 'bmp', 'BMP')\n",
        "                    os.remove(name)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset_folder[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_folder)\n",
        "\n",
        "bird_data = BirdDataset()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting bird-species-classification.zip\n",
            "Resizing images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-29503913206e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mbird_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBirdDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-29503913206e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, zip_file, size, train, upload)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# in the DataLoader, but it will read the full-resolution files from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# every time before resizing them, making training slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpostfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-29503913206e>\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, path, size)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'bmp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BMP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(image, size, method, bleed, centering)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# resize the image and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIqeYz_N7prC",
        "outputId": "753c384b-b2b9-4cfd-c619-8c597cdf2cad"
      },
      "source": [
        "# Example download command for dataset found here: https://www.kaggle.com/akash2907/bird-species-classification\r\n",
        "!kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intel-image-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jHFdToeDtIF"
      },
      "source": [
        "#########################\n",
        "# Implement your own Dataset\n",
        "#########################\n",
        "\n",
        "class DogDataset(Dataset):\n",
        "    def __init__(self, zip_file='intel-image-classification.zip', size=256, train=True, upload=False):\n",
        "        super(DogDataset, self).__init__()\n",
        "        \n",
        "        self.train = train\n",
        "        extract_dir = os.path.splitext(zip_file)[0]\n",
        "        if not os.path.exists(extract_dir):\n",
        "            os.makedirs(extract_dir)\n",
        "            self.extract_zip(zip_file, extract_dir)\n",
        "            # Resize the images - originally they are high resolution. We could do this\n",
        "            # in the DataLoader, but it will read the full-resolution files from disk\n",
        "            # every time before resizing them, making training slow\n",
        "            self.resize(extract_dir, size=size)\n",
        "\n",
        "        postfix = 'train' if train else 'test'\n",
        "\n",
        "        self.dataset_folder = datasets.ImageFolder( os.path.join(extract_dir, 'seg_train', 'seg_train'), transform=transforms.Compose([transforms.ToTensor()]), )\n",
        "\n",
        "    def extract_zip(self, zip_file, extract_dir):\n",
        "        print(\"Extracting\", zip_file)\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "    def resize(self, path, size=256):\n",
        "        \"\"\"Resizes all images in place\"\"\"\n",
        "        print(\"Resizing images\")\n",
        "        dirs = os.walk(path)\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for item in files:\n",
        "                name = os.path.join(root, item)\n",
        "                if os.path.isfile(name):\n",
        "                    im = Image.open(name)\n",
        "                    im = ImageOps.fit(im, (size, size))\n",
        "                    im.save(name[:-3] + 'bmp', 'BMP')\n",
        "                    os.remove(name)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset_folder[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1000\n",
        "\n",
        "dog_data = DogDataset()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vJVbYcAJAf2"
      },
      "source": [
        "### 1.2 Wrap a pretrained ResNet in an `nn.Module` (30 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMOzGDND9FD1"
      },
      "source": [
        "#### Done:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLvmDHbl9IyG"
      },
      "source": [
        "- Make a model class that inherits from `nn.Module`\n",
        "- Wrap a pretrained ResNet and swap out the last layer of that network with a layer that maps to the number of classes in your new dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOtl8z8G9wbr"
      },
      "source": [
        "#### Make your model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY-XU4Mwas0j"
      },
      "source": [
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, num_classes, start_frozen=False):\n",
        "        super(CustomResNet, self).__init__()\n",
        "\n",
        "        # Part 1.2\n",
        "        # Load the model - make sure it is pre-trained\n",
        "        self.resnet_model = resnet152(pretrained=True)\n",
        "\n",
        "        # Part 1.4\n",
        "        if start_frozen:\n",
        "            # Turn off all gradients of the resnet\n",
        "            for parameters in self.resnet_model.parameters():\n",
        "                parameters.requires_grad = False\n",
        "        \n",
        "        # Part 1.2\n",
        "        # Look at the code of torchvision.models.resnet152 (or print the ResNet object) to find the name of the attribute to override (the last layer of the ResNet)\n",
        "        # Override the output linear layer of the neural network to map to the correct number of classes. Note that this new layer has requires_grad = True\n",
        "        self.resnet_model.fc = nn.Linear(self.resnet_model.fc.in_features, num_classes)\n",
        "        self.resnet_model.fc.requires_grad = True\n",
        "        pass\n",
        "        \n",
        "    def unfreeze(self, n_layers):\n",
        "        # Part 1.4\n",
        "        # Turn on gradients for the last n_layers\n",
        "        parameters = list(self.resnet_model.parameters())\n",
        "        # The first two layers will always be unfrozen.\n",
        "        for i in range(len(parameters) - n_layers, len(parameters)):\n",
        "            parameters[i].requires_grad = True\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Part 1.2\n",
        "        # Pass x through the resnet\n",
        "        return( self.resnet_model(x) )\n",
        "        pass"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Krh0eYy18R9"
      },
      "source": [
        "### 1.3 Read through and run this training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOGrrw2gbIPf"
      },
      "source": [
        "def accuracy(y_hat, y_truth):\n",
        "    \"\"\"Gets average accuracy of a vector of predictions\"\"\"\n",
        "    \n",
        "    preds = torch.argmax(y_hat, dim=1)\n",
        "    acc = torch.mean((preds == y_truth).float())\n",
        "    return acc\n",
        "\n",
        "def evaluate(model, objective, val_loader, device):\n",
        "    \"\"\"Gets average accuracy and loss for the validation set\"\"\"\n",
        "\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    # model.eval() so that batchnorm and dropout work in eval mode\n",
        "    model.eval()\n",
        "    # torch.no_grad() to turn off computation graph creation. This allows for temporal\n",
        "    # and spatial complexity improvements, which allows for larger validation batch \n",
        "    # sizes so itâ€™s recommended\n",
        "    with torch.no_grad():\n",
        "        for x, y_truth in val_loader:\n",
        "\n",
        "            x, y_truth = x.to(device), y_truth.to(device)\n",
        "            y_hat = model(x)\n",
        "            val_loss = objective(y_hat, y_truth)\n",
        "            val_acc = accuracy(y_hat, y_truth)\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "            val_accs.append(val_acc)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    return torch.mean(torch.Tensor(val_losses)), torch.mean(torch.Tensor(val_accs))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKESMcKi2E_f"
      },
      "source": [
        "def train(start_frozen=False, model_unfreeze=0):\n",
        "    \"\"\"Fine-tunes a CNN\n",
        "    Args:\n",
        "        start_frozen (bool): whether to start with the network weights frozen.\n",
        "        model_unfreeze (int): the maximum number of network layers to unfreeze\n",
        "    \"\"\"\n",
        "    epochs = 20\n",
        "    # Start with a very low learning rate\n",
        "    lr = .00005\n",
        "    val_every = 3\n",
        "    num_classes = 16\n",
        "    batch_size = 32\n",
        "    device = torch.device('cuda:0')\n",
        "\n",
        "    # Data\n",
        "    train_dataset = DogDataset(upload=True, train=True)\n",
        "    val_dataset = DogDataset(upload=True, train=False)\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              shuffle=True,\n",
        "                              num_workers=8,\n",
        "                              batch_size=batch_size)\n",
        "    val_loader = DataLoader(val_dataset,\n",
        "                              shuffle=True,\n",
        "                              num_workers=8,\n",
        "                              batch_size=batch_size)\n",
        "    \n",
        "    # Model\n",
        "    model = CustomResNet(num_classes, start_frozen=start_frozen).to(device)\n",
        "    \n",
        "    # Objective\n",
        "    objective = nn.CrossEntropyLoss()\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-1)\n",
        "\n",
        "    # Progress bar\n",
        "    pbar = tqdm(total=len(train_loader) * epochs)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    cnt = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Implement model unfreezing\n",
        "        if epoch < model_unfreeze:\n",
        "            # Part 1.4\n",
        "            # Unfreeze the last layers, one more each epoch\n",
        "            model.unfreeze(epoch + 1)\n",
        "            pass\n",
        "        \n",
        "        for x, y_truth in train_loader:\n",
        "        \n",
        "            x, y_truth = x.to(device), y_truth.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_hat = model(x)\n",
        "            train_loss = objective(y_hat, y_truth)\n",
        "            train_acc = accuracy(y_hat, y_truth)\n",
        "\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_accs.append(train_acc)\n",
        "            train_losses.append(train_loss.item())\n",
        "\n",
        "            if cnt % val_every == 0:\n",
        "                val_loss, val_acc = evaluate(model, objective, val_loader, device)\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            pbar.set_description('train loss:{:.4f}, train accuracy:{:.4f}.'.format(train_loss.item(), train_acc))\n",
        "            pbar.update(1)\n",
        "            cnt += 1\n",
        "\n",
        "    pbar.close()\n",
        "    plt.subplot(121)\n",
        "    plt.plot(np.arange(len(train_accs)), train_accs, label='Train Accuracy')\n",
        "    plt.plot(np.arange(len(train_accs), step=val_every), val_accs, label='Val Accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(122)\n",
        "    plt.plot(np.arange(len(train_losses)), train_losses, label='Train Loss')\n",
        "    plt.plot(np.arange(len(train_losses), step=val_every), val_losses, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.show()  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "fvnxeLotchiH",
        "outputId": "f49e2e49-b65c-4982-ce37-02bde0dd636b"
      },
      "source": [
        "train(start_frozen=False, model_unfreeze=0)  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "train loss:0.0038, train accuracy:1.0000.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 640/640 [44:36<00:00,  4.18s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEDv_-H7BvM0"
      },
      "source": [
        "### 1.4 Implement Unfreezing (1 hr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH5mQBaa-_0b"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_YmE1pe-6LF"
      },
      "source": [
        "Unfreezing is a technique that can be helpful when fine tuning a CNN for a more difficult task with a large amount of data.\n",
        "\n",
        "The idea is that if we allow the network to tweak the earliest layers immediately, before the last FCL has been trained at all, the earliest layers will forget all of the useful features that they learned in order  to provide features that are helpful for the (untrained) FCL.\n",
        "\n",
        "So, rather than training all of the model weights at once, we learn the last fully connected layer, then train that layer together with the second-to-last layer, gradually adding layers until we reach the first layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMKRI77_-8nc"
      },
      "source": [
        "#### DONE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaUc8BTYC1bz"
      },
      "source": [
        "- Modify your model class by setting the `requires_grad` attribute of the ResNet to `False`. (but keep `requires_grad = True` for the last layer).\n",
        "- Add a member function to you model class that allows the user to unfreeze weights in the training loop. See [this github gist](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c) for reference.\n",
        "- Modify your training loop to add logic that calls the `unfreeze` function of the model class (unfreeze one layer every epoch).\n",
        "- Call your train function to fine-tune the ResNet on your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBT5jgifC7Im"
      },
      "source": [
        "#### Call your train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Mg9ySEO_BNDx",
        "outputId": "c1ebc172-c584-4c6e-b8ad-c84169f29f77"
      },
      "source": [
        "############################\n",
        "# train with unfreezing here (should be a single call to your train function)\n",
        "############################\n",
        "train(start_frozen=True, model_unfreeze=8) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "train loss:0.0087, train accuracy:1.0000.: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 640/640 [38:07<00:00,  3.57s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZItH2lX7k4Yt"
      },
      "source": [
        "You may not see any improvement for your classification task, but unfreezing can help convergence for more difficult image classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAXHAUf3EEiE"
      },
      "source": [
        "## 2 Fine-tune a language model - (15 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu9usOxtjFHL"
      },
      "source": [
        "In this section you will use the gpt-2-simple package [here](https://github.com/minimaxir/gpt-2-simple) to fine-tune the GPT-2 language model on a domain of your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K7F19SPQo6U"
      },
      "source": [
        "### 2.1 Generate text from an the pretrained GPT-2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YLXvK51RnuL"
      },
      "source": [
        "#### Run this code to generate text from a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDNOb_H5IRvH",
        "outputId": "d31dfd10-25a3-4821-e556-43053754d7b7"
      },
      "source": [
        "!pip install gpt-2-simple\n",
        "\n",
        "# the transformers package is built on top of Tensorflow, and the default TF version \n",
        "# for Colab will soon switch to 2.x. We remedy this with the following magic method\n",
        "%tensorflow_version 1.x \n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/c9/44fe420225244ab9e3f2938a1d11651681078cf72f7444c66d0ea49f1320/gpt_2_simple-0.7.2.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.19.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/7d/55784e894ee0cde2474fb977ffd1651e74e840a9f92e1d847f7e3115d5ec/toposort-1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.2-cp37-none-any.whl size=23621 sha256=5db022871741a66e4c6f2d3af2203faacba5d0ed988915168464fd34a4cd2812\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/1d/15/c87a4302a6c7273ce1b4f282bec3c6877fb2f521535d87d30f\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.2 toposort-1.6\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aRJ-c9uRMOa",
        "outputId": "473d7780-edb0-4d9d-c721-03b02f20bbbf"
      },
      "source": [
        "# This line is necessary to be able to run a new tf session\n",
        "tf.reset_default_graph()\n",
        "# The medium-sized model. IF you run out of memory, try \"124M\" instead\n",
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "\tprint(f\"Downloading {model_name} model...\")\n",
        "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "gpt2.generate(sess, model_name=model_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 535Mit/s]                                                      "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading 124M model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fetching encoder.json: 1.05Mit [00:00, 3.25Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 324Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:09, 54.7Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 357Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.64Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 4.68Mit/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Copper Kings, Inc. (NYSE: COK), a leading silver- and gold-based manufacturer of silver-plated metal products, announced today that it has acquired the strategic, marketing and engineering divisions of Copper Kings Inc. for $8.5 billion.\n",
            "\n",
            "Copper Kings is a leading silver- and gold-based manufacturer of silver-plated metal products, which include silver-plated metal products with a nickel-cadmium alloy to produce silver plated metal products. Copper Kings is a leader in the silver-plated metal industry and has revenues of $80.5 billion. Copper Kings is headquartered in the City of Berkeley, California; is an internationally recognized gold-based producer of silver-plated metal products. Copper Kings is recognized as one of the largest and most talented silver-plated metal producers on the planet.\n",
            "\n",
            "The acquisition of Copper Kings is an important step forward for Copper Kings, which is looking to expand its global presence by increasing its sales and sales leads, and its customers by expanding its global focus on silver-plated metal products, particularly silver plated metal products with nickel-cadmium alloy. In addition, Copper Kings is among the largest silver-plated metal manufacturers in the world.\n",
            "\n",
            "Copper Kings and Copper Kings Inc. will be valued at $1.5 billion and $1.8 billion, respectively, for the purchase of Copper Kings. The transaction is expected to close in the third quarter of 2012.\n",
            "\n",
            "\"We are thrilled to welcome Copper Kings to our growing platform,\" said Anne McNally, co-founder and chairman of Copper Kings. \"Copper Kings is one of the largest metal producers in the world and we are looking forward to expanding our global presence by expanding our sales and sales leads, and our customers by expanding our global focus on silver-plated metal products, especially silver plated metal products with nickel-cadmium alloy.\"\n",
            "\n",
            "\"We are excited to bring Copper Kings to the world of silver plated metal,\" said Jeff Menniot, vice president and chief executive officer, Copper Kings. \"We are excited to assist Copper Kings with its growing market share in the silver-plated metal industry and to provide it and its customers with the resources they need to grow their silver-plated metal business. We are excited to continue our long-term strategic partnership with Copper Kings and we look forward to continuing to invest in the Silver-Plated Metal Industry, which is the next great era of silver-plated metal products.\"\n",
            "\n",
            "Copper Kings' Silver Plated Metal Industry Packages\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated Metal Products\n",
            "\n",
            "Silver Plated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHmjSVf_FNHv"
      },
      "source": [
        "### 2.2 Download a text dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPXJkNubFyY6"
      },
      "source": [
        "#### Done:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWkuRjbcFzwb"
      },
      "source": [
        "- Use the provided functions to download your own text dataset\n",
        "- [Project Gutenberg](https://www.gutenberg.org/) is a nice starting point for raw text corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD45m3IwF9hh"
      },
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "88a013142de04e2cb1f9e2892da8266a",
            "45e046c53e8c4ed7b28e4e2e4b14eca4",
            "2415c3503a364773aa247e4f3594198c",
            "d92ab09330ac487bb808acffbd05697e",
            "40f606ed1d314a418a41a11e611ed72f",
            "c1a69607289f4407be259e4eb4ad9e4d",
            "ecf2bab890ab41e1a697c14f4e1820db",
            "ea9e2f68b9ca4d559dd54e66843784b2"
          ]
        },
        "id": "ESltl2QM5nxw",
        "outputId": "93b05e38-3fd6-4d2b-9f6a-69bef481d6e4"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "def extract_zip(zip_path, remove_finished=True):\n",
        "    print('Extracting {}'.format(zip_path))\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(zip_path.replace('.zip', ''))\n",
        "    if remove_finished:\n",
        "        os.remove(zip_path)\n",
        "\n",
        "def download_dataset(url, root='../data'):\n",
        "    if not os.path.exists(os.path.join(root, 'text')):\n",
        "        os.makedirs(os.path.join(root))\n",
        "        datasets.utils.download_url(url, root, 'text.zip', None)\n",
        "        extract_zip(os.path.join(root, 'text.zip'))\n",
        "    return os.path.join(root, 'text')\n",
        "\n",
        "##########################################\n",
        "# Set the url for your dataset here,\n",
        "# move the dataset to the desired location\n",
        "##########################################\n",
        "url = 'https://www.gutenberg.org/files/15210/15210.zip'\n",
        "download_dataset(url)\n",
        "!mv /data/text/30.txt /data/text/bible.txt\n",
        "!ls ../data/text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.gutenberg.org/files/15210/15210.zip to ../data/text.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88a013142de04e2cb1f9e2892da8266a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=165140.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data/text.zip\n",
            "mv: cannot stat '/data/text/30.txt': No such file or directory\n",
            "15210.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBIEBaemCAuH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usQE-rSPZq_X"
      },
      "source": [
        "### 2.3 Fine-tune GPT-2 on your own dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoA0tZZCa_1k"
      },
      "source": [
        "#### Done:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoU6ML1mbgjP"
      },
      "source": [
        "- Swap out the dataset parameter with the path to your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pa5vFJ5EUjv"
      },
      "source": [
        "#### Train on your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuQ5snl4LuS0",
        "outputId": "d7692da2-5d3b-4a51-89b5-7db9c1360861"
      },
      "source": [
        "# This line is necessary to be able to run a new tf session if one has already been run\n",
        "tf.reset_default_graph()\n",
        "# Start a session\n",
        "sess = gpt2.start_tf_sess()\n",
        "# Fine tune `model_name` on `data`\n",
        "###################################\n",
        "# Swap out the `dataset` parameter with the path to your text dataset\n",
        "###################################\n",
        "gpt2.finetune(sess,\n",
        "              dataset='../data/text/15210.txt',\n",
        "              model_name=model_name,\n",
        "              restore_from='latest',\n",
        "              steps=500)   # steps is max number of training steps\n",
        "\n",
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 102379 tokens\n",
            "Training...\n",
            "[1 | 8.50] loss=3.80 avg=3.80\n",
            "[2 | 10.74] loss=3.65 avg=3.72\n",
            "[3 | 12.98] loss=3.78 avg=3.74\n",
            "[4 | 15.23] loss=3.78 avg=3.75\n",
            "[5 | 17.48] loss=3.47 avg=3.69\n",
            "[6 | 19.74] loss=3.64 avg=3.68\n",
            "[7 | 22.01] loss=3.75 avg=3.69\n",
            "[8 | 24.29] loss=3.16 avg=3.62\n",
            "[9 | 26.56] loss=3.14 avg=3.57\n",
            "[10 | 28.84] loss=3.50 avg=3.56\n",
            "[11 | 31.13] loss=3.60 avg=3.57\n",
            "[12 | 33.41] loss=3.61 avg=3.57\n",
            "[13 | 35.71] loss=3.62 avg=3.57\n",
            "[14 | 38.02] loss=3.59 avg=3.57\n",
            "[15 | 40.33] loss=3.45 avg=3.57\n",
            "[16 | 42.65] loss=3.60 avg=3.57\n",
            "[17 | 44.99] loss=3.45 avg=3.56\n",
            "[18 | 47.33] loss=3.37 avg=3.55\n",
            "[19 | 49.67] loss=3.36 avg=3.54\n",
            "[20 | 52.02] loss=3.18 avg=3.52\n",
            "[21 | 54.38] loss=3.10 avg=3.50\n",
            "[22 | 56.73] loss=3.58 avg=3.50\n",
            "[23 | 59.06] loss=3.52 avg=3.50\n",
            "[24 | 61.39] loss=3.18 avg=3.49\n",
            "[25 | 63.71] loss=3.17 avg=3.47\n",
            "[26 | 66.01] loss=3.43 avg=3.47\n",
            "[27 | 68.33] loss=2.80 avg=3.44\n",
            "[28 | 70.62] loss=3.26 avg=3.43\n",
            "[29 | 72.93] loss=3.18 avg=3.42\n",
            "[30 | 75.22] loss=3.23 avg=3.42\n",
            "[31 | 77.51] loss=2.98 avg=3.40\n",
            "[32 | 79.80] loss=2.63 avg=3.37\n",
            "[33 | 82.09] loss=3.25 avg=3.37\n",
            "[34 | 84.37] loss=3.20 avg=3.36\n",
            "[35 | 86.64] loss=3.02 avg=3.35\n",
            "[36 | 88.93] loss=3.28 avg=3.35\n",
            "[37 | 91.20] loss=3.32 avg=3.35\n",
            "[38 | 93.48] loss=3.01 avg=3.34\n",
            "[39 | 95.76] loss=3.17 avg=3.33\n",
            "[40 | 98.04] loss=3.34 avg=3.33\n",
            "[41 | 100.31] loss=3.06 avg=3.32\n",
            "[42 | 102.59] loss=2.91 avg=3.31\n",
            "[43 | 104.87] loss=3.11 avg=3.31\n",
            "[44 | 107.15] loss=3.33 avg=3.31\n",
            "[45 | 109.44] loss=2.86 avg=3.30\n",
            "[46 | 111.72] loss=3.12 avg=3.29\n",
            "[47 | 114.00] loss=3.27 avg=3.29\n",
            "[48 | 116.29] loss=3.25 avg=3.29\n",
            "[49 | 118.58] loss=2.70 avg=3.27\n",
            "[50 | 120.88] loss=2.65 avg=3.26\n",
            "[51 | 123.18] loss=2.92 avg=3.25\n",
            "[52 | 125.48] loss=3.27 avg=3.25\n",
            "[53 | 127.78] loss=3.07 avg=3.25\n",
            "[54 | 130.08] loss=3.09 avg=3.24\n",
            "[55 | 132.39] loss=3.26 avg=3.24\n",
            "[56 | 134.70] loss=2.82 avg=3.23\n",
            "[57 | 137.01] loss=2.80 avg=3.22\n",
            "[58 | 139.33] loss=2.95 avg=3.22\n",
            "[59 | 141.63] loss=2.85 avg=3.21\n",
            "[60 | 143.94] loss=2.83 avg=3.20\n",
            "[61 | 146.25] loss=2.93 avg=3.19\n",
            "[62 | 148.56] loss=2.92 avg=3.19\n",
            "[63 | 150.88] loss=3.08 avg=3.19\n",
            "[64 | 153.18] loss=3.21 avg=3.19\n",
            "[65 | 155.49] loss=2.78 avg=3.18\n",
            "[66 | 157.79] loss=2.47 avg=3.16\n",
            "[67 | 160.10] loss=2.85 avg=3.16\n",
            "[68 | 162.41] loss=3.04 avg=3.15\n",
            "[69 | 164.71] loss=2.92 avg=3.15\n",
            "[70 | 167.00] loss=2.80 avg=3.14\n",
            "[71 | 169.30] loss=2.29 avg=3.13\n",
            "[72 | 171.59] loss=3.15 avg=3.13\n",
            "[73 | 173.89] loss=2.77 avg=3.12\n",
            "[74 | 176.18] loss=3.21 avg=3.12\n",
            "[75 | 178.49] loss=2.13 avg=3.10\n",
            "[76 | 180.79] loss=2.79 avg=3.10\n",
            "[77 | 183.08] loss=2.85 avg=3.09\n",
            "[78 | 185.37] loss=2.90 avg=3.09\n",
            "[79 | 187.68] loss=2.86 avg=3.08\n",
            "[80 | 189.97] loss=3.00 avg=3.08\n",
            "[81 | 192.26] loss=2.89 avg=3.08\n",
            "[82 | 194.55] loss=2.91 avg=3.08\n",
            "[83 | 196.84] loss=2.60 avg=3.07\n",
            "[84 | 199.14] loss=2.88 avg=3.06\n",
            "[85 | 201.45] loss=2.70 avg=3.06\n",
            "[86 | 203.75] loss=2.44 avg=3.05\n",
            "[87 | 206.05] loss=2.64 avg=3.04\n",
            "[88 | 208.34] loss=2.87 avg=3.04\n",
            "[89 | 210.64] loss=2.62 avg=3.03\n",
            "[90 | 212.94] loss=2.89 avg=3.03\n",
            "[91 | 215.24] loss=2.79 avg=3.02\n",
            "[92 | 217.53] loss=2.79 avg=3.02\n",
            "[93 | 219.83] loss=2.28 avg=3.01\n",
            "[94 | 222.13] loss=2.63 avg=3.00\n",
            "[95 | 224.43] loss=2.25 avg=2.99\n",
            "[96 | 226.73] loss=2.64 avg=2.98\n",
            "[97 | 229.04] loss=2.63 avg=2.98\n",
            "[98 | 231.34] loss=2.56 avg=2.97\n",
            "[99 | 233.66] loss=2.51 avg=2.96\n",
            "[100 | 235.96] loss=2.62 avg=2.96\n",
            "======== SAMPLE 1 ========\n",
            " wings. You have seen and heard.\n",
            "They are but the faces, the folds of folds on which the\n",
            "shape of men lives, and they are the faces of men who do not know\n",
            "the real face. That is the tragedy of men. The faces of men\n",
            "are that face of the people and what is face is that face of\n",
            "men,--dark, dark man. That is the tragedy of men; dark, dark man.\n",
            "For all these great tragedies, white, black, yellow, gray, and\n",
            "yellow and brown men, even men who are,--man to man, man to man, man unto man.\n",
            "\n",
            "For all that has been in store for humanity since the day of creation was\n",
            "not its face, but the black, brown, and white man for its\n",
            "face and for its human form,--a face dark, a face green, a face yellow.\n",
            "\n",
            "There are other faces--such as these are all men, black and brown,\n",
            "and brown and crimson, a face crimson, but a face dark, a\n",
            "face brown, and a face brown; and this is how the great catastrophe that\n",
            "has been wrought on us yesterday became manifest,--one man and one\n",
            "character and a face dark, a face dark, a face brown, a face red, both of\n",
            "white, both of black, the full breadth of a man, a full breadth of\n",
            "men, a world wide open. Let us not allow that darkness as something\n",
            "that can and must be prevented,--that this world is dark. Let us not allow\n",
            "that the world is vast and vast and vast,--the whole thing. Let us\n",
            "leave the whole matter of the face and the man,--we will not allow the world that\n",
            "lies in store for humanity to be destroyed. We leave, too, the world that is not\n",
            "here with the face--the human face and face brown, the human face, the\n",
            "face green, the human man, the man who walks for the love of his\n",
            "self, the woman. We will let all that brown man's dark face has in store for\n",
            "the world and leave it alone,--its form, its face, its eyes, its bones; its\n",
            "memories, its dreams--its pain. Let us leave all but the face and go on\n",
            "going,--leaving all that man was, his wife, his children, his\n",
            "beauties, his flesh, and his mind. Let us, then, leave the world and let\n",
            "the face and the man,--the man through the face and the person.\n",
            "\n",
            "We have seen some of the giants, some of the giants of heaven and\n",
            "worlds, but few of these are men. They lie and lie and lie.\n",
            "\n",
            "I say it, men. It is not all their tragedy or tragedy's tragedy. We have\n",
            "seen some of the giants,--many of them mighty and great. None is bigger and\n",
            "greater; none has lived more nobly and more nobly, but the one\n",
            "the other, the great giant, who stands at the threshold, alone among the giants\n",
            "of time, death, and beauty. Here he is greater than all men, above all,\n",
            "because of his love of man and his love of woman; here he is bigger than\n",
            "all men, above all, because of his hatred of woman, his love of\n",
            "woman, his hatred of the woman within. Above all, as men and\n",
            "women, we are sons and daughters of God. We are God's sons, sons of\n",
            "brothers who did not know each other's faces and made not a thing\n",
            "under heaven, but beneath the earth and beneath the sea. Alone, therefore,\n",
            "do we live and to glory we must live as sons of God.\n",
            "\n",
            "We must go and die as sons of God! We must not die, we must not die.\n",
            "\n",
            "We must rise again. We may raise again one day and live as a\n",
            "man. We may not live as man, save in the final act of creation and\n",
            "that last act of great tragedy and tragedy of men, but we\n",
            "must not sink into the slumbers of fear and despair. We may be\n",
            "above the pale of time and eternity, before even the stars, before\n",
            "the suns and the moons of creation, before the great men of God; but\n",
            "if we are ever there, there might be light and life and laughter beneath\n",
            "the great, unspoken, veil of time and eternity, if we did not\n",
            "kill!\n",
            "\n",
            "If, then, our immortality is an end and the immortality of the\n",
            "end is not, then, then, God's immortality is not the end. He never ends\n",
            "it. He has other ends for what he is doing and he ends it and\n",
            "he never ends his other ends.\n",
            "\n",
            "If, then, our immortality is a gift of God and not a gift of men,\n",
            "\n",
            "\n",
            "[101 | 248.62] loss=2.77 avg=2.96\n",
            "[102 | 250.93] loss=2.57 avg=2.95\n",
            "[103 | 253.24] loss=2.50 avg=2.94\n",
            "[104 | 255.54] loss=2.39 avg=2.93\n",
            "[105 | 257.86] loss=2.22 avg=2.92\n",
            "[106 | 260.16] loss=2.49 avg=2.92\n",
            "[107 | 262.48] loss=2.28 avg=2.91\n",
            "[108 | 264.78] loss=2.26 avg=2.90\n",
            "[109 | 267.09] loss=2.54 avg=2.89\n",
            "[110 | 269.41] loss=2.38 avg=2.88\n",
            "[111 | 271.71] loss=2.32 avg=2.88\n",
            "[112 | 274.01] loss=2.29 avg=2.87\n",
            "[113 | 276.32] loss=2.48 avg=2.86\n",
            "[114 | 278.63] loss=2.16 avg=2.85\n",
            "[115 | 280.93] loss=2.33 avg=2.84\n",
            "[116 | 283.24] loss=2.04 avg=2.83\n",
            "[117 | 285.54] loss=2.48 avg=2.83\n",
            "[118 | 287.84] loss=2.46 avg=2.82\n",
            "[119 | 290.15] loss=2.92 avg=2.82\n",
            "[120 | 292.46] loss=2.40 avg=2.82\n",
            "[121 | 294.76] loss=2.44 avg=2.81\n",
            "[122 | 297.07] loss=2.59 avg=2.81\n",
            "[123 | 299.37] loss=2.45 avg=2.80\n",
            "[124 | 301.68] loss=2.42 avg=2.80\n",
            "[125 | 303.98] loss=2.31 avg=2.79\n",
            "[126 | 306.28] loss=2.27 avg=2.78\n",
            "[127 | 308.59] loss=2.61 avg=2.78\n",
            "[128 | 310.89] loss=1.93 avg=2.77\n",
            "[129 | 313.19] loss=2.27 avg=2.76\n",
            "[130 | 315.49] loss=2.04 avg=2.75\n",
            "[131 | 317.79] loss=1.90 avg=2.74\n",
            "[132 | 320.09] loss=2.09 avg=2.73\n",
            "[133 | 322.39] loss=2.19 avg=2.73\n",
            "[134 | 324.69] loss=2.21 avg=2.72\n",
            "[135 | 327.00] loss=2.38 avg=2.71\n",
            "[136 | 329.30] loss=2.37 avg=2.71\n",
            "[137 | 331.61] loss=2.18 avg=2.70\n",
            "[138 | 333.91] loss=1.83 avg=2.69\n",
            "[139 | 336.21] loss=1.98 avg=2.68\n",
            "[140 | 338.52] loss=1.96 avg=2.67\n",
            "[141 | 340.82] loss=1.91 avg=2.66\n",
            "[142 | 343.12] loss=1.89 avg=2.65\n",
            "[143 | 345.44] loss=1.72 avg=2.64\n",
            "[144 | 347.74] loss=1.83 avg=2.63\n",
            "[145 | 350.06] loss=1.63 avg=2.62\n",
            "[146 | 352.36] loss=1.79 avg=2.61\n",
            "[147 | 354.66] loss=2.02 avg=2.60\n",
            "[148 | 356.97] loss=1.72 avg=2.59\n",
            "[149 | 359.27] loss=1.76 avg=2.58\n",
            "[150 | 361.58] loss=1.85 avg=2.57\n",
            "[151 | 363.88] loss=1.98 avg=2.56\n",
            "[152 | 366.19] loss=1.55 avg=2.55\n",
            "[153 | 368.48] loss=1.64 avg=2.53\n",
            "[154 | 370.78] loss=1.53 avg=2.52\n",
            "[155 | 373.10] loss=2.09 avg=2.52\n",
            "[156 | 375.40] loss=1.84 avg=2.51\n",
            "[157 | 377.70] loss=1.68 avg=2.50\n",
            "[158 | 380.00] loss=1.15 avg=2.48\n",
            "[159 | 382.30] loss=1.67 avg=2.47\n",
            "[160 | 384.60] loss=1.86 avg=2.46\n",
            "[161 | 386.91] loss=1.61 avg=2.45\n",
            "[162 | 389.21] loss=1.41 avg=2.44\n",
            "[163 | 391.51] loss=1.55 avg=2.43\n",
            "[164 | 393.81] loss=1.77 avg=2.42\n",
            "[165 | 396.12] loss=1.59 avg=2.41\n",
            "[166 | 398.42] loss=1.45 avg=2.40\n",
            "[167 | 400.71] loss=1.41 avg=2.39\n",
            "[168 | 403.02] loss=2.01 avg=2.38\n",
            "[169 | 405.31] loss=1.55 avg=2.37\n",
            "[170 | 407.62] loss=1.42 avg=2.36\n",
            "[171 | 409.92] loss=1.84 avg=2.35\n",
            "[172 | 412.22] loss=1.80 avg=2.35\n",
            "[173 | 414.52] loss=1.76 avg=2.34\n",
            "[174 | 416.83] loss=1.60 avg=2.33\n",
            "[175 | 419.13] loss=1.61 avg=2.32\n",
            "[176 | 421.43] loss=1.30 avg=2.31\n",
            "[177 | 423.73] loss=1.43 avg=2.30\n",
            "[178 | 426.04] loss=0.94 avg=2.28\n",
            "[179 | 428.34] loss=1.29 avg=2.27\n",
            "[180 | 430.64] loss=1.55 avg=2.26\n",
            "[181 | 432.95] loss=1.63 avg=2.25\n",
            "[182 | 435.25] loss=1.56 avg=2.25\n",
            "[183 | 437.56] loss=1.63 avg=2.24\n",
            "[184 | 439.86] loss=1.92 avg=2.23\n",
            "[185 | 442.16] loss=1.18 avg=2.22\n",
            "[186 | 444.47] loss=1.33 avg=2.21\n",
            "[187 | 446.77] loss=1.10 avg=2.20\n",
            "[188 | 449.07] loss=1.09 avg=2.19\n",
            "[189 | 451.38] loss=1.27 avg=2.17\n",
            "[190 | 453.68] loss=1.30 avg=2.16\n",
            "[191 | 455.98] loss=1.21 avg=2.15\n",
            "[192 | 458.28] loss=1.57 avg=2.15\n",
            "[193 | 460.59] loss=1.26 avg=2.14\n",
            "[194 | 462.90] loss=1.31 avg=2.13\n",
            "[195 | 465.20] loss=1.16 avg=2.11\n",
            "[196 | 467.51] loss=1.24 avg=2.10\n",
            "[197 | 469.81] loss=1.45 avg=2.10\n",
            "[198 | 472.12] loss=0.82 avg=2.08\n",
            "[199 | 474.42] loss=1.32 avg=2.07\n",
            "[200 | 476.72] loss=1.39 avg=2.07\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "A third problem arose, namely, the indefinite expansion of family life. We know now what great workhouses in Europe were capable of after World War; and we know a great deal less about the beginnings of the modern family today than we may have had trusty\n",
            "friends in the days of the Renaissance and modern women. And yet the paradox stands: If the\n",
            "modern family is modern, then what is the modern family?\n",
            "\n",
            "The modern family is a social system built on a foundation of classes, classes, and\n",
            "religions. Its foundation is the sweat and tears of generations of\n",
            "workers. Every generation must pass through a process of elaborating on the\n",
            "seamings of its present circumstances. In doing so, the present generation must\n",
            "look upon itself to be sure,--but the future must not be seen as a\n",
            "thing but as a chance occasion.\n",
            "\n",
            "How far can this program survive revolution? There is no certain\n",
            "path. The path of the modern family must involve a broadening of the\n",
            "struggles for larger and larger ends, for wider and wider methods of\n",
            "exploiting new capabilities of a larger and wider variety of workers\n",
            "and methods of exploiting new human capabilities of new labor\n",
            "power. This broadening must be done in a wide and particular way so that\n",
            "it no longer alienates workers from broadening their tasks or throws\n",
            "workers off-balances. There has been no systematic and systematic\n",
            "scientific survey of the method of modernizing the family. With\n",
            "this in hand, as has been indicated, can we say with any confidence that the Revolution\n",
            "in 1849 was a 'great awakening'?\n",
            "\n",
            "In this area the field of modern modernizing has its limits. Today the world\n",
            "seems very deliberately divided between two camps: those in\n",
            "industrialised nations who are using up a world which used up only half\n",
            "the world's output of that day, and those who are on the capitalist\n",
            "upper hand and eager to capitalize on it. This new industrial\n",
            "type has no clear categories of goods to measure human values or of\n",
            "human activities--they are simply \"men.\" The great mass of workers in that\n",
            "world are simply not using up the world they started, and the\n",
            "social problems of that day have for the moment been solved. But the question\n",
            "of industrial revolution has given rise to a movement in the industrial\n",
            "opposition called mass democracy, and this democratic movement has swept through\n",
            "every empire since the world of history. The world wide\n",
            "meeting of this movement is hardly under way. But the question of politics is\n",
            "probably destined to become one of the most important factors advancing\n",
            "the organization of the future world.\n",
            "\n",
            "The Crisis of Democracy\n",
            "\n",
            "\n",
            "The Crisis of Democracy\n",
            "\n",
            "\n",
            "\n",
            "The Crisis of Democracy\n",
            "\n",
            "    Three centuries after its foundation, Egypt was an\n",
            "    Empire ruled by a tyrant called Cleanthes.    Three centuries after its\n",
            "   establishment, a kingdom lay undefended beneath the waves of the\n",
            "    Nile, with a court of kings, a people strong and\n",
            "    Thamthras strong beneath the yoke of the Moabites.\n",
            "   Three centuries after its establishment, Egypt was split between two\n",
            "    Continents: the Moabites, widely reviled by the Persians, held\n",
            "    Egypt for two centuries under the nom de guerre of Theodosius\n",
            "    Andus, under which the empire was strong and Thane ruled from\n",
            "    Theocris.    Three centuries after its establishment, Egypt was\n",
            "    Rhesus and Anrae without the Pharaoh and Asia without the\n",
            "    Sphinx,--an independent empire divided between the two world-old\n",
            "    Empires.   But a new and distinct religion was born in\n",
            "    Egypt: that is, a new religion based on the worship of one god\n",
            "    over another, one God over another,--one Egyptian over another\n",
            "    God, with a vast, mysterious arm that may sweep\n",
            "    up from the seas or down from Mount Sumer--\"\n",
            "\n",
            "That ancient mother nation was named after Cleanthes, king of Egypt, as the\n",
            "    epithet was widely interpreted and written about it, and the\n",
            "    modern usage of the word \"Egyptian\" in the early\n",
            "    days of English spread the idea of a Persian mother country\n",
            "    with a written version of her own written in the early\n",
            "    day.   This mother nation was named after Cleanthes, king of Egypt, as the\n",
            "    epithet was widely interpreted and written about it, and the\n",
            "    modern usage of the word \"Egyptian\" in the early days of English spread the\n",
            "    idea of a Persian mother nation with a written edition of her own written in\n",
            "\n",
            "\n",
            "[201 | 488.23] loss=1.14 avg=2.06\n",
            "[202 | 490.53] loss=1.11 avg=2.04\n",
            "[203 | 492.84] loss=1.19 avg=2.03\n",
            "[204 | 495.14] loss=1.48 avg=2.03\n",
            "[205 | 497.44] loss=1.15 avg=2.02\n",
            "[206 | 499.74] loss=0.79 avg=2.00\n",
            "[207 | 502.04] loss=0.95 avg=1.99\n",
            "[208 | 504.34] loss=0.97 avg=1.98\n",
            "[209 | 506.63] loss=1.27 avg=1.97\n",
            "[210 | 508.94] loss=1.01 avg=1.96\n",
            "[211 | 511.24] loss=0.73 avg=1.95\n",
            "[212 | 513.54] loss=1.07 avg=1.94\n",
            "[213 | 515.84] loss=0.94 avg=1.93\n",
            "[214 | 518.14] loss=1.20 avg=1.92\n",
            "[215 | 520.44] loss=1.18 avg=1.91\n",
            "[216 | 522.74] loss=0.69 avg=1.90\n",
            "[217 | 525.03] loss=0.86 avg=1.88\n",
            "[218 | 527.34] loss=0.62 avg=1.87\n",
            "[219 | 529.63] loss=1.03 avg=1.86\n",
            "[220 | 531.93] loss=0.58 avg=1.85\n",
            "[221 | 534.23] loss=1.12 avg=1.84\n",
            "[222 | 536.54] loss=1.19 avg=1.83\n",
            "[223 | 538.84] loss=0.73 avg=1.82\n",
            "[224 | 541.13] loss=0.75 avg=1.81\n",
            "[225 | 543.43] loss=1.22 avg=1.80\n",
            "[226 | 545.72] loss=0.93 avg=1.79\n",
            "[227 | 548.03] loss=0.93 avg=1.78\n",
            "[228 | 550.33] loss=0.55 avg=1.77\n",
            "[229 | 552.62] loss=0.89 avg=1.76\n",
            "[230 | 554.93] loss=0.54 avg=1.74\n",
            "[231 | 557.23] loss=1.17 avg=1.74\n",
            "[232 | 559.53] loss=0.66 avg=1.73\n",
            "[233 | 561.83] loss=0.68 avg=1.71\n",
            "[234 | 564.13] loss=0.90 avg=1.70\n",
            "[235 | 566.43] loss=0.62 avg=1.69\n",
            "[236 | 568.73] loss=0.65 avg=1.68\n",
            "[237 | 571.04] loss=0.91 avg=1.67\n",
            "[238 | 573.35] loss=0.87 avg=1.66\n",
            "[239 | 575.65] loss=0.51 avg=1.65\n",
            "[240 | 577.95] loss=1.33 avg=1.65\n",
            "[241 | 580.25] loss=0.60 avg=1.64\n",
            "[242 | 582.56] loss=0.99 avg=1.63\n",
            "[243 | 584.86] loss=0.99 avg=1.62\n",
            "[244 | 587.17] loss=0.71 avg=1.61\n",
            "[245 | 589.47] loss=0.63 avg=1.60\n",
            "[246 | 591.78] loss=0.54 avg=1.59\n",
            "[247 | 594.09] loss=0.82 avg=1.58\n",
            "[248 | 596.39] loss=0.59 avg=1.57\n",
            "[249 | 598.71] loss=0.95 avg=1.56\n",
            "[250 | 601.02] loss=0.65 avg=1.55\n",
            "[251 | 603.33] loss=0.65 avg=1.54\n",
            "[252 | 605.63] loss=0.56 avg=1.53\n",
            "[253 | 607.93] loss=0.90 avg=1.53\n",
            "[254 | 610.23] loss=0.68 avg=1.52\n",
            "[255 | 612.53] loss=0.64 avg=1.51\n",
            "[256 | 614.83] loss=0.40 avg=1.50\n",
            "[257 | 617.14] loss=0.65 avg=1.49\n",
            "[258 | 619.44] loss=0.35 avg=1.47\n",
            "[259 | 621.75] loss=0.70 avg=1.47\n",
            "[260 | 624.06] loss=0.69 avg=1.46\n",
            "[261 | 626.37] loss=0.68 avg=1.45\n",
            "[262 | 628.67] loss=0.71 avg=1.44\n",
            "[263 | 630.98] loss=0.63 avg=1.43\n",
            "[264 | 633.29] loss=0.46 avg=1.42\n",
            "[265 | 635.59] loss=0.67 avg=1.41\n",
            "[266 | 637.89] loss=0.63 avg=1.41\n",
            "[267 | 640.20] loss=0.43 avg=1.39\n",
            "[268 | 642.50] loss=0.41 avg=1.38\n",
            "[269 | 644.80] loss=0.51 avg=1.37\n",
            "[270 | 647.11] loss=0.63 avg=1.37\n",
            "[271 | 649.41] loss=0.62 avg=1.36\n",
            "[272 | 651.72] loss=0.47 avg=1.35\n",
            "[273 | 654.03] loss=0.43 avg=1.34\n",
            "[274 | 656.34] loss=0.50 avg=1.33\n",
            "[275 | 658.64] loss=0.40 avg=1.32\n",
            "[276 | 660.95] loss=0.30 avg=1.31\n",
            "[277 | 663.26] loss=0.52 avg=1.30\n",
            "[278 | 665.56] loss=0.44 avg=1.29\n",
            "[279 | 667.86] loss=0.28 avg=1.28\n",
            "[280 | 670.17] loss=0.38 avg=1.27\n",
            "[281 | 672.47] loss=0.41 avg=1.26\n",
            "[282 | 674.78] loss=0.43 avg=1.25\n",
            "[283 | 677.08] loss=0.50 avg=1.25\n",
            "[284 | 679.38] loss=0.37 avg=1.24\n",
            "[285 | 681.68] loss=0.41 avg=1.23\n",
            "[286 | 683.99] loss=0.38 avg=1.22\n",
            "[287 | 686.30] loss=0.36 avg=1.21\n",
            "[288 | 688.61] loss=0.50 avg=1.20\n",
            "[289 | 690.91] loss=0.41 avg=1.19\n",
            "[290 | 693.21] loss=0.33 avg=1.18\n",
            "[291 | 695.51] loss=0.35 avg=1.18\n",
            "[292 | 697.82] loss=0.36 avg=1.17\n",
            "[293 | 700.12] loss=0.39 avg=1.16\n",
            "[294 | 702.43] loss=0.51 avg=1.15\n",
            "[295 | 704.74] loss=0.34 avg=1.14\n",
            "[296 | 707.04] loss=0.43 avg=1.14\n",
            "[297 | 709.35] loss=0.29 avg=1.13\n",
            "[298 | 711.64] loss=0.48 avg=1.12\n",
            "[299 | 713.96] loss=0.25 avg=1.11\n",
            "[300 | 716.25] loss=0.21 avg=1.10\n",
            "======== SAMPLE 1 ========\n",
            " This \"great leap\" toward modern slavery that the nation has made\n",
            "in its day to select from among the natives a name for itself.\n",
            "Slavery in the United States from Browning until O'Hare became a\n",
            "black hell in 1820 when half the plantation were impudently\n",
            "browned for six years instead of the twelve the forefathers had paid.\n",
            "\n",
            "Then came North, East, South, and North again,--the nine\n",
            "states which Jefferson Davis calls to mind the kings of Egypt,\n",
            "the sea, and the land of Canaan. The nine kingdoms were ironized out\n",
            "in twelve days, with Egypt, Ammon, Ambar, and Tellis set before their\n",
            "wrath. The Abyssinia, Thrace, and Rhodeses were brought to\n",
            "her knees before her and broken up into smaller, moreconventional, and lesser\n",
            "states,--South Africa before her and Eritrea before her and\n",
            "Benin before her.\n",
            "\n",
            "That great cataclysm of history,--that one glorious death in\n",
            "one hundred and forty one,--that in which nine mighty\n",
            "nations, vaulting for worldhood against eachother, clasped their souls\n",
            "deeply\n",
            "into eachother's darkest fists and cried: We are weak,\n",
            "we do not do battle for you; we are our own people; we are\n",
            "\"Greater,\" as one white man put it, \"against the whole\n",
            "world\" and said, \"are you that kind? Do you want to be one of\n",
            "that mob? Do you want to be called what you are? Do you want to be\n",
            "what you are? Do you want to be a soldier and be for what you are?\n",
            "WILLIAM DAVIES!\"\n",
            "\n",
            "They did exactly that. They fought two mighty battles,--the\n",
            "first was a war against Canaan, the second a war against\n",
            "Africa,--the earth was raised on the ninth day of Nefertari\n",
            "(Earth God summoned the Israelites to war on the earth), and the earth\n",
            "was turned (to Adam's and Eve's wedding) about twelve degrees North and\n",
            "South of that due north-south sun-kissed in the American Negro'\n",
            "hair. In thirteen days there would be forty-three million men, or\n",
            "35%, of the black men murdered in human history.\n",
            "\n",
            "Of that death forty-four million Negro men, or 20%, of the\n",
            "merged dead were born. Of those forty-four millions a\n",
            "half-million were white and of those a half-million black were\n",
            "born. Of this world twelve million Negro lived,--96%.\n",
            "\n",
            "But was it not inevitable this destiny, this sudden\n",
            "events, that in this dark midnight it came to earth? Not far from\n",
            "New England, in Massachusetts, and in Massachusetts County,\n",
            "West Virginia, and on the coast of Texas and as far as the Mississippi,\n",
            "there happened the earth-shaking birth of a Negro nation. It was so\n",
            "ordinarily un-American a time and place that there arose in it no\n",
            "great surprise that rises of race hatreds are so frequent as in\n",
            "Africa and in the nation's final determination to make the world\n",
            "a better, freer, and better race.\n",
            "\n",
            "The very foundation of American Negroism was here; its history its\n",
            "formative period; its thought and expression what it meant in the\n",
            "fourth and final century--golden, pure, pure genius put forth to\n",
            "make the race a great, immortal thing. Here it is,--a\n",
            "child star of human development, unable, bereft of its father, its\n",
            "mother, or even bent and squeezed between the worlds is its destiny molded\n",
            "by vast and uncorrelated chance. Nothing could be more American and\n",
            "whatever less the world would be-gethers would come, if they could, but the\n",
            "stars of American Negroism would gleam in the American\n",
            "Asiatic Nations and their endless dance would be a joy to behold.\n",
            "\n",
            "        *        *       *\n",
            "\n",
            "Here at last our Balkan friends have a future for themselves and for\n",
            "us, with the protection of the Amer- icas. We surrender with a crash of\n",
            "desperate thunder, thrusting at our heels with the might of wild beasts.\n",
            "Whither? To Africa, to the black seas, sinking with each\n",
            "burden of Calcutta, to the entrails of Kentucky, to the endless yawning\n",
            "of the Mississippi, to the end of the World? Whither? To the ablest, nameless\n",
            "woman in Ohio or the daughter of the poor slave in Mississippi,\n",
            "or to the conquering Irish head of Connaught or the daughter of\n",
            "the scorned black woman South Carolina, we may beseech God to create\n",
            "this beautiful land of her people independent and human.\n",
            "\n",
            "God, who made this\n",
            "\n",
            "[301 | 727.87] loss=0.32 avg=1.09\n",
            "[302 | 730.17] loss=0.55 avg=1.09\n",
            "[303 | 732.47] loss=0.38 avg=1.08\n",
            "[304 | 734.78] loss=0.22 avg=1.07\n",
            "[305 | 737.08] loss=0.26 avg=1.06\n",
            "[306 | 739.38] loss=0.22 avg=1.05\n",
            "[307 | 741.68] loss=0.25 avg=1.05\n",
            "[308 | 743.99] loss=0.53 avg=1.04\n",
            "[309 | 746.29] loss=0.17 avg=1.03\n",
            "[310 | 748.59] loss=0.30 avg=1.02\n",
            "[311 | 750.89] loss=0.33 avg=1.02\n",
            "[312 | 753.20] loss=0.33 avg=1.01\n",
            "[313 | 755.50] loss=0.53 avg=1.00\n",
            "[314 | 757.80] loss=0.41 avg=1.00\n",
            "[315 | 760.11] loss=0.53 avg=0.99\n",
            "[316 | 762.41] loss=0.32 avg=0.99\n",
            "[317 | 764.71] loss=0.39 avg=0.98\n",
            "[318 | 767.01] loss=0.56 avg=0.98\n",
            "[319 | 769.32] loss=0.31 avg=0.97\n",
            "[320 | 771.61] loss=0.28 avg=0.96\n",
            "[321 | 773.91] loss=0.33 avg=0.95\n",
            "[322 | 776.22] loss=0.33 avg=0.95\n",
            "[323 | 778.52] loss=0.40 avg=0.94\n",
            "[324 | 780.82] loss=0.35 avg=0.94\n",
            "[325 | 783.12] loss=0.22 avg=0.93\n",
            "[326 | 785.43] loss=0.18 avg=0.92\n",
            "[327 | 787.73] loss=0.29 avg=0.91\n",
            "[328 | 790.03] loss=0.34 avg=0.91\n",
            "[329 | 792.33] loss=0.18 avg=0.90\n",
            "[330 | 794.64] loss=0.28 avg=0.89\n",
            "[331 | 796.95] loss=0.34 avg=0.89\n",
            "[332 | 799.25] loss=0.27 avg=0.88\n",
            "[333 | 801.55] loss=0.23 avg=0.88\n",
            "[334 | 803.85] loss=0.21 avg=0.87\n",
            "[335 | 806.16] loss=0.29 avg=0.86\n",
            "[336 | 808.47] loss=0.16 avg=0.86\n",
            "[337 | 810.76] loss=0.29 avg=0.85\n",
            "[338 | 813.06] loss=0.25 avg=0.84\n",
            "[339 | 815.37] loss=0.14 avg=0.84\n",
            "[340 | 817.67] loss=0.19 avg=0.83\n",
            "[341 | 819.97] loss=0.16 avg=0.82\n",
            "[342 | 822.28] loss=0.23 avg=0.82\n",
            "[343 | 824.58] loss=0.25 avg=0.81\n",
            "[344 | 826.88] loss=0.25 avg=0.80\n",
            "[345 | 829.19] loss=0.19 avg=0.80\n",
            "[346 | 831.50] loss=0.23 avg=0.79\n",
            "[347 | 833.80] loss=0.21 avg=0.79\n",
            "[348 | 836.10] loss=0.14 avg=0.78\n",
            "[349 | 838.40] loss=0.13 avg=0.77\n",
            "[350 | 840.70] loss=0.31 avg=0.77\n",
            "[351 | 843.00] loss=0.18 avg=0.76\n",
            "[352 | 845.30] loss=0.16 avg=0.76\n",
            "[353 | 847.61] loss=0.18 avg=0.75\n",
            "[354 | 849.90] loss=0.16 avg=0.74\n",
            "[355 | 852.21] loss=0.17 avg=0.74\n",
            "[356 | 854.51] loss=0.14 avg=0.73\n",
            "[357 | 856.81] loss=0.12 avg=0.73\n",
            "[358 | 859.12] loss=0.11 avg=0.72\n",
            "[359 | 861.42] loss=0.22 avg=0.71\n",
            "[360 | 863.73] loss=0.15 avg=0.71\n",
            "[361 | 866.03] loss=0.14 avg=0.70\n",
            "[362 | 868.33] loss=0.12 avg=0.70\n",
            "[363 | 870.63] loss=0.16 avg=0.69\n",
            "[364 | 872.94] loss=0.24 avg=0.69\n",
            "[365 | 875.24] loss=0.16 avg=0.68\n",
            "[366 | 877.55] loss=0.19 avg=0.68\n",
            "[367 | 879.85] loss=0.13 avg=0.67\n",
            "[368 | 882.15] loss=0.10 avg=0.67\n",
            "[369 | 884.45] loss=0.16 avg=0.66\n",
            "[370 | 886.76] loss=0.15 avg=0.65\n",
            "[371 | 889.06] loss=0.15 avg=0.65\n",
            "[372 | 891.37] loss=0.14 avg=0.64\n",
            "[373 | 893.67] loss=0.17 avg=0.64\n",
            "[374 | 895.97] loss=0.21 avg=0.64\n",
            "[375 | 898.28] loss=0.18 avg=0.63\n",
            "[376 | 900.58] loss=0.13 avg=0.63\n",
            "[377 | 902.88] loss=0.14 avg=0.62\n",
            "[378 | 905.18] loss=0.15 avg=0.62\n",
            "[379 | 907.48] loss=0.17 avg=0.61\n",
            "[380 | 909.78] loss=0.15 avg=0.61\n",
            "[381 | 912.08] loss=0.22 avg=0.60\n",
            "[382 | 914.39] loss=0.10 avg=0.60\n",
            "[383 | 916.69] loss=0.13 avg=0.59\n",
            "[384 | 918.99] loss=0.13 avg=0.59\n",
            "[385 | 921.29] loss=0.09 avg=0.58\n",
            "[386 | 923.59] loss=0.15 avg=0.58\n",
            "[387 | 925.90] loss=0.12 avg=0.57\n",
            "[388 | 928.21] loss=0.18 avg=0.57\n",
            "[389 | 930.51] loss=0.14 avg=0.57\n",
            "[390 | 932.82] loss=0.14 avg=0.56\n",
            "[391 | 935.12] loss=0.13 avg=0.56\n",
            "[392 | 937.43] loss=0.11 avg=0.55\n",
            "[393 | 939.74] loss=0.15 avg=0.55\n",
            "[394 | 942.04] loss=0.12 avg=0.54\n",
            "[395 | 944.34] loss=0.15 avg=0.54\n",
            "[396 | 946.64] loss=0.13 avg=0.54\n",
            "[397 | 948.95] loss=0.13 avg=0.53\n",
            "[398 | 951.25] loss=0.10 avg=0.53\n",
            "[399 | 953.56] loss=0.13 avg=0.52\n",
            "[400 | 955.86] loss=0.10 avg=0.52\n",
            "======== SAMPLE 1 ========\n",
            " studied from her own fingers and they thrust themselves at me.\n",
            "My face lit with the enticing image of that priceless priceless ivory serpent!\n",
            "\n",
            "What a day it had been! I took the Orion seat and glanced at the\n",
            "sky. I looked into the veiled face of the Sphinx and thought, OH! In a YEARS! In YEARS!\n",
            "\n",
            "Ah! by the POWER OF WORK I had made a house of!--a mighty house!\n",
            "\n",
            "My life was a strange, long process of transforming, speckling upon transforming\n",
            "upon my body. The hinges of the attic chimney creaked behind the\n",
            "throne, the volume of the air conditioner leaped within the cracks, and I\n",
            "gazed about the place until I came to the home I loved,--a\n",
            "displaced place, peonian in face and thought, a cubious wonder, furnished\n",
            "with all the necessities of life and love. Around me was the\n",
            "living, breathing soul of God,--living in a world worth living for!\n",
            "\n",
            "My days were not terrible,--they were rather normal ones. The\n",
            "joy of work was gone, and my sharp senses became counterfeit; my\n",
            "degradation was retributary; I was liked and regarded as the saviour of\n",
            "the poor,--the clang of oppression crushing your strength and laughter. I\n",
            "was the rector of Georgetown, and I was revered around\n",
            "the world. What looked like disaster on the bright side was instead\n",
            "flooding the world with loving brotherhood and love. It was\n",
            "the golden calf--the decent, decent calf who once stood high\n",
            "among you and whose soft bones you shared a life of worship. You sat\n",
            "compelled to help him shoulder the mounting ravages of the world.\n",
            "\n",
            "When the bishops of Washington, D.C. heard of my decision to leave Washington,\n",
            "they immediately imposed its all upon me. I had studied and\n",
            "worked in different cities during my years at Washington, and they told me\n",
            "that the pressure was great. For three or four years I was to stay in\n",
            "Chicago, Boston, and New York, at a salary of at least $10 an\n",
            "hour, and at a salary and compliment paid for my good studies. In\n",
            "this I did marvel.\n",
            "\n",
            "Then disconcerted I and ran away to a beautiful Brooklyn where, with the\n",
            "colonies of D.C. at my feet, I welcomed Professor Widtley\n",
            "of Widtley's Oriental School to teach me further Africa.\n",
            "\n",
            "In 1887 I was chosen as Field Teacher of the Year for laying down\n",
            "scientific principles as I had lived my life taught truths. The\n",
            "roping of the century had evidently come to a grinding halt,--surging\n",
            "against the wall between pessimism and complacency. So much for\n",
            "experience and study, so much soculated the year and year\n",
            "forth in our method of life and in our language.\n",
            "\n",
            "With Washington gone, D.C. was the cold horror of Asia. We\n",
            "embraced a high caste of lawyers, clergy, and military men, with\n",
            "many exceptions uncivil and unable to love. We ended\n",
            "ourperialitize our neighbor to the core,--slavery in every sense of\n",
            "the word. We severely curbed the freedom of speech and the\n",
            "property of the press, taxes the ownership of lands, taxes the\n",
            "establishment of dynasties, taxes the owning of ships, plots, and\n",
            "settlements, taxes the training and equipping of servant\n",
            "and fellow slaves, taxes the holding and transporting of funds, and\n",
            "takes from the treasury all the confiscated goods from Egypt and\n",
            "the Near East.\n",
            "\n",
            "Against such a background, the future President had made some\n",
            "difficult decisions in the War and in foreign relations. In 1812 had\n",
            "cut a path of social equality for Negroes in each sex,--an\n",
            "integral equality that called for little coercion or indemnity from\n",
            "pain or suffering. He also wanted an unitively right to call native\n",
            "Africans \"natives\" as well as Negroes! This he succeeded by\n",
            "prompting and pausing procreation,--creation that freed the child from\n",
            "the pettiness of its parents, from the squeeze of its work and play,\n",
            "and from the strain of family and spiritual adventure.\n",
            "\n",
            "So, also, with the colored people excluded, but after a thorough and systematic\n",
            "going back into nature, through love, sacrifice, and vestment, they\n",
            "were looked upon as living, breathing beings, distinct from men and\n",
            "not all differences from race had engendered in them.\n",
            "\n",
            "President Lincoln had already indicated to the North a number of points of\n",
            "interest. He came to the United States with some earnestness and\n",
            "suggested they should ask the permission of the U.S. Congress to\n",
            "take a look at the \"Negroes in the North.\" In addition to\n",
            "\n",
            "[401 | 967.43] loss=0.12 avg=0.51\n",
            "[402 | 969.74] loss=0.12 avg=0.51\n",
            "[403 | 972.05] loss=0.15 avg=0.51\n",
            "[404 | 974.35] loss=0.14 avg=0.50\n",
            "[405 | 976.65] loss=0.16 avg=0.50\n",
            "[406 | 978.96] loss=0.16 avg=0.50\n",
            "[407 | 981.25] loss=0.13 avg=0.49\n",
            "[408 | 983.56] loss=0.19 avg=0.49\n",
            "[409 | 985.86] loss=0.13 avg=0.49\n",
            "[410 | 988.17] loss=0.11 avg=0.48\n",
            "[411 | 990.47] loss=0.09 avg=0.48\n",
            "[412 | 992.78] loss=0.11 avg=0.47\n",
            "[413 | 995.07] loss=0.15 avg=0.47\n",
            "[414 | 997.37] loss=0.11 avg=0.47\n",
            "[415 | 999.67] loss=0.14 avg=0.46\n",
            "[416 | 1001.98] loss=0.11 avg=0.46\n",
            "[417 | 1004.28] loss=0.12 avg=0.46\n",
            "[418 | 1006.58] loss=0.11 avg=0.45\n",
            "[419 | 1008.89] loss=0.10 avg=0.45\n",
            "[420 | 1011.18] loss=0.10 avg=0.45\n",
            "[421 | 1013.48] loss=0.39 avg=0.45\n",
            "[422 | 1015.78] loss=0.11 avg=0.44\n",
            "[423 | 1018.08] loss=0.12 avg=0.44\n",
            "[424 | 1020.39] loss=0.09 avg=0.44\n",
            "[425 | 1022.69] loss=0.12 avg=0.43\n",
            "[426 | 1024.99] loss=0.10 avg=0.43\n",
            "[427 | 1027.30] loss=0.10 avg=0.43\n",
            "[428 | 1029.59] loss=0.08 avg=0.42\n",
            "[429 | 1031.89] loss=0.12 avg=0.42\n",
            "[430 | 1034.19] loss=0.12 avg=0.42\n",
            "[431 | 1036.49] loss=0.10 avg=0.41\n",
            "[432 | 1038.79] loss=0.16 avg=0.41\n",
            "[433 | 1041.10] loss=0.11 avg=0.41\n",
            "[434 | 1043.40] loss=0.15 avg=0.40\n",
            "[435 | 1045.70] loss=0.10 avg=0.40\n",
            "[436 | 1047.99] loss=0.14 avg=0.40\n",
            "[437 | 1050.30] loss=0.09 avg=0.40\n",
            "[438 | 1052.60] loss=0.13 avg=0.39\n",
            "[439 | 1054.90] loss=0.10 avg=0.39\n",
            "[440 | 1057.20] loss=0.09 avg=0.39\n",
            "[441 | 1059.50] loss=0.09 avg=0.38\n",
            "[442 | 1061.80] loss=0.17 avg=0.38\n",
            "[443 | 1064.11] loss=0.08 avg=0.38\n",
            "[444 | 1066.41] loss=0.11 avg=0.38\n",
            "[445 | 1068.72] loss=0.11 avg=0.37\n",
            "[446 | 1071.02] loss=0.09 avg=0.37\n",
            "[447 | 1073.32] loss=0.09 avg=0.37\n",
            "[448 | 1075.63] loss=0.14 avg=0.37\n",
            "[449 | 1077.92] loss=0.08 avg=0.36\n",
            "[450 | 1080.23] loss=0.13 avg=0.36\n",
            "[451 | 1082.53] loss=0.12 avg=0.36\n",
            "[452 | 1084.82] loss=0.08 avg=0.35\n",
            "[453 | 1087.12] loss=0.09 avg=0.35\n",
            "[454 | 1089.42] loss=0.10 avg=0.35\n",
            "[455 | 1091.73] loss=0.11 avg=0.35\n",
            "[456 | 1094.03] loss=0.11 avg=0.34\n",
            "[457 | 1096.33] loss=0.08 avg=0.34\n",
            "[458 | 1098.63] loss=0.09 avg=0.34\n",
            "[459 | 1100.94] loss=0.09 avg=0.34\n",
            "[460 | 1103.25] loss=0.15 avg=0.33\n",
            "[461 | 1105.55] loss=0.09 avg=0.33\n",
            "[462 | 1107.85] loss=0.11 avg=0.33\n",
            "[463 | 1110.15] loss=0.10 avg=0.33\n",
            "[464 | 1112.45] loss=0.11 avg=0.33\n",
            "[465 | 1114.76] loss=0.09 avg=0.32\n",
            "[466 | 1117.07] loss=0.11 avg=0.32\n",
            "[467 | 1119.37] loss=0.08 avg=0.32\n",
            "[468 | 1121.66] loss=0.10 avg=0.32\n",
            "[469 | 1123.97] loss=0.08 avg=0.31\n",
            "[470 | 1126.27] loss=0.09 avg=0.31\n",
            "[471 | 1128.58] loss=0.09 avg=0.31\n",
            "[472 | 1130.88] loss=0.11 avg=0.31\n",
            "[473 | 1133.18] loss=0.08 avg=0.31\n",
            "[474 | 1135.48] loss=0.10 avg=0.30\n",
            "[475 | 1137.78] loss=0.06 avg=0.30\n",
            "[476 | 1140.08] loss=0.08 avg=0.30\n",
            "[477 | 1142.38] loss=0.09 avg=0.30\n",
            "[478 | 1144.68] loss=0.12 avg=0.29\n",
            "[479 | 1146.98] loss=0.11 avg=0.29\n",
            "[480 | 1149.28] loss=0.10 avg=0.29\n",
            "[481 | 1151.58] loss=0.11 avg=0.29\n",
            "[482 | 1153.88] loss=0.10 avg=0.29\n",
            "[483 | 1156.19] loss=0.08 avg=0.29\n",
            "[484 | 1158.49] loss=0.10 avg=0.28\n",
            "[485 | 1160.79] loss=0.09 avg=0.28\n",
            "[486 | 1163.10] loss=0.07 avg=0.28\n",
            "[487 | 1165.40] loss=0.11 avg=0.28\n",
            "[488 | 1167.70] loss=0.12 avg=0.28\n",
            "[489 | 1170.01] loss=0.10 avg=0.27\n",
            "[490 | 1172.30] loss=0.10 avg=0.27\n",
            "[491 | 1174.61] loss=0.08 avg=0.27\n",
            "[492 | 1176.92] loss=0.09 avg=0.27\n",
            "[493 | 1179.22] loss=0.10 avg=0.27\n",
            "[494 | 1181.51] loss=0.09 avg=0.27\n",
            "[495 | 1183.82] loss=0.09 avg=0.26\n",
            "[496 | 1186.11] loss=0.09 avg=0.26\n",
            "[497 | 1188.41] loss=0.11 avg=0.26\n",
            "[498 | 1190.72] loss=0.09 avg=0.26\n",
            "[499 | 1193.03] loss=0.08 avg=0.26\n",
            "[500 | 1195.34] loss=0.10 avg=0.26\n",
            "Saving checkpoint/run1/model-500\n",
            "the\n",
            "world, from the sea, sailing as far as the Spanish Main, whence\n",
            "the dead men of Africa come and feast upon the rich tapestry of\n",
            "America.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "_The Princess of the Hither Isles_\n",
            "\n",
            "\n",
            "Her soul was beautiful, wherefore she kept it veiled in lightly-laced\n",
            "humility and fear, out of which peered anxiously and anon the white and\n",
            "blue and pale-gold of her face,-beautiful as daybreak or as the laughing\n",
            "of a child. She sat in the Hither Isles, well walled between the This\n",
            "and Now, upon a low and silver throne, and leaned upon its armposts,\n",
            "sadly looking upward toward the sun. Today the Hither Isles are\n",
            "worthwhile, for they are flat and swampy, but yesterday they felt\n",
            "like kingdoms gone terrible, with every nerve and fiber of their being severed.\n",
            "Down into the Hither Isles they have rested, wallowed, and\n",
            "spoke silently about their brokenhearted selves. Down into the\n",
            "Amazon they lie and lie no longer, but lie and weep, as they\n",
            "veilled sighs as they knew how,--in the great Shell at the foot of the\n",
            "mountains, and as they went they passed by a great, red mausoleum, almighty,\n",
            "above the pale, silent sun.\n",
            "\n",
            "He came this morning with his lone star, and he presented us with a\n",
            "great, silver SKY. He was the first to leave the tower and glide down\n",
            "to the ether. We were not expecting him so flaunted as this,--but he came. He\n",
            "introduced himself. He was. We had come to talk of him. He was the\n",
            "ideal son, the one who could play the captaincy of his people and\n",
            "make them great colonies of good Europeans. We had looked forward to that\n",
            "firstborn in bright Africa, the king of the Hither Isles, who would not\n",
            "spit in our faces and say that he was only \"a priest.\" We had looked forward to\n",
            "that firstborn as a brother and a friend and, indeed, our first white king.\n",
            "But he came. He came quickly. He began by saying that he was\n",
            "trying to be \"practical.\" He meant to be \"practical\" in the extreme\n",
            "enthdimension of things,--practicing with patience and care. He meant to\n",
            "be \"practical\" with the world and the masses. He did not mean to be \"practical\" with\n",
            "the ignorant; he meant to be practical with them. He did not want to be \"practical\n",
            "with the world\" and, therefore, he was willing to go \"soft\" into \"hard\" territory.\n",
            "\n",
            "He asked, and was willing to go, many men and women, even a large\n",
            "and presumably profitable profit, as \"practicals.\" Some, they were told, did\n",
            "their \"holy work\" and some not. Some even claimed priesthoods. Some even\n",
            "claimed positions at the AlkmaRite. Some, but not all, believed these things\n",
            "and others did not. When one looked at the \"princes,\" how many were\n",
            "hearts, how many hearts, how many heads, he left us with one great\n",
            "question: \"What is the Prince's Office?\" He that was called \"princeship\" in\n",
            "public life did not live to that day. However, the third and final day\n",
            "of our lives saw another look and another thought: \"Prince,\n",
            "what is this wonder of the world? There is no such thing as a\n",
            "practical\" administrator of Princeseses or Grand Principals, for that is a\n",
            "man's duty, but only a proper one when he is of the type. Thus we\n",
            "learn that public servants are paid, on average, three times as much as their\n",
            "private servants. This wage is paid in millions, but paid when the\n",
            "services become more efficient and when the needs of the group become\n",
            "more than the needs of the individual worker. Inefficient machinery and\n",
            "systems make inefficient work inefficient, and inefficient people--even efficient\n",
            "workers--are killed. When this happens, how many of us turn to the\n",
            "Prince of Peace? He is the herald of civilization,--he rules and invokes\n",
            "princes, assigns great wishes and elaborate systems of government,\n",
            "and sends out his citizens to sea to do his bidding. But where has\n",
            "this Prince of Peace gone? He has not even been formally\n",
            "appointed administrator of the white world's industry,--\n",
            "not by the green and mighty nation-states he hasappointed,--but by the\n",
            "white world's world-wide trade and colonial policy which\n",
            "the world-mastery has handed to white supremacy in Africa and\n",
            "the Americas.\n",
            "\n",
            "The real reason for the gap in pay between the two worlds is\n",
            "conceived of course as work\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}